{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyISr3c6L8cY"
   },
   "source": [
    "# Adversarial Search: Playing \"Mean\" Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "All student names in group: Safwan Kader, Jerry Xiao, Dylan Lai\n",
    "\n",
    "I understand that my submission needs to be my own group's work: SK, JX, DL\n",
    "\n",
    "I understand that ChatGPT / Copilot / other AI tools are not allowed: SK, JX, DL\n",
    "\n",
    "Points: 10\n",
    "\n",
    "Complete this notebook and submit it (save/print as pdf). The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play \"Mean\" Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
    "\n",
    "> **The mean part:** This game has an additional rule. Every time it is a player's turn, the player can decide to instead of playing a new disk, take a bottom row disk of the opponent and place it back in the top of the same column. All disks above the removed disk will fall down one position and the removed one will be placed on top. Note that a player can only move an _opponent's disc_ that is in the _bottom row_ of the board. **Further, you are not allowed to play a mean move if your opponent just played one.** This ensures the game will end at some point. This also may affect the definition of a state, compared with standard Connect 4.\n",
    "\n",
    "If a mean move causes both players to win, the game immediately ends and it is a tie, even if one player has more connect-4s than the other one. If a mean move causes one player to win, then the game also ends and the player with the connect-4 is the winner.\n",
    "\n",
    "Note that normal [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
    "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuWbcK6gL8cZ"
   },
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "**Define the components of the search problem associated with this game:**\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzLitKOdL8cf"
   },
   "source": [
    "- **Initial State (Sâ‚€):** \n",
    "  - The initial state is an empty Connect 4 board with no discs placed.\n",
    "  \n",
    "- **Actions (A):** \n",
    "  - Actions include dropping a disc in one of the seven columns or performing a mean move in one of the columns where the opponent has a disc in the bottom row.\n",
    "  \n",
    "- **Transition Model (Result function):** \n",
    "  - The transition model defines how the state changes based on the action taken. It returns the new state after applying the action. In this case, the transition model will show how the board will change after a mean move or regular move. \n",
    "  \n",
    "  - *Result(s,a) -> a'* where s is the current state and a is the action taken. a' is the new state. \n",
    "  \n",
    "- **Test for the terminal state:** \n",
    "  - We can define a function ```is_terminal``` which checks whether the game has reached a terminal state. This includes checking for a winner or a tie (full board). Terminal states only require at least one winner or ties. If multiple wins are detected, they will be ignored.\n",
    "  \n",
    "- **Utility for terminal states:** \n",
    "  - The utility function assigns utility values based on the outcome of the game. It returns a positive value if Max wins, a negative value if Min wins, and 0 for a tie.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHDORt8_L8cg"
   },
   "source": [
    "**How big is the state space? Give an estimate and explain it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_GIsO80L8cg"
   },
   "source": [
    "The state space is estimated as 3^(6*7) since each cell can have three states (empty, player 1, player 2) on a 6x7 board.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ci9AS2QL8ch"
   },
   "source": [
    "**How big is the game tree that minimax search will go through? Give an estimate and explain it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTkWu4ZiL8ci"
   },
   "source": [
    "The game tree is estimated based on the branching factor (number of possible actions) raised to the depth of the tree. The depth is the maximum number of moves until the end of the game, which is typically less than 42 (6 rows * 7 columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u66LNfUEL8ci"
   },
   "source": [
    "## Task 2: Game Environment and Random Agent [3 point]\n",
    "\n",
    "You can use a numpy character array as the board. Note that the following function can create boards of different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gFoRCZefL8cj",
    "outputId": "00cf5cf5-25c4-407c-8ce4-c0a215ce24ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCCwVya8L8cj"
   },
   "source": [
    "Instead of colors (red and yellow), you can use 1 and -1 to represent the players Max and Min. Make sure that your agent functions all have the from: `agent_type(state, player = 1)`, where board is the current board position and player is the player (1, -1) whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtsGKQPsL8ck"
   },
   "source": [
    "Visualization code by Randolph Rankin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dRChZkdZL8ck",
    "outputId": "93cf152b-5e40-4a66-b68f-a3ba69d0a94e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "\n",
    "board = [[0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0,-1,-1, 1,-1, 0, 0]]\n",
    "\n",
    "visualize(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOa_fihRL8ck"
   },
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8sDMBWFtL8ck"
   },
   "outputs": [],
   "source": [
    "def move(board, action, player):\n",
    "    new_board = [row.copy() for row in board]\n",
    "\n",
    "    if action[0] == 'drop':\n",
    "        column = action[1]\n",
    "        for row in range(len(new_board) - 1, -1, -1):\n",
    "            if new_board[row][column] == 0:\n",
    "                new_board[row][column] = player \n",
    "                break\n",
    "    elif action[0] == 'mean':\n",
    "        column = action[1]\n",
    "        row = len(new_board) - 1\n",
    "        while board[row][column] != 0 and row > 0:\n",
    "            board[row][column] = board[row - 1][column]\n",
    "            row -= 1\n",
    "        board[row][column] = player * -1\n",
    "\n",
    "    return new_board\n",
    "\n",
    "\n",
    "def utility(board):\n",
    "    pass\n",
    "\n",
    "def check_board(state):\n",
    "    # function to check if a sequence of values in a line is a winning sequence\n",
    "    def is_winning_sequence(sequence):\n",
    "        return any(sum(sequence[i:i+4]) == 4 or sum(sequence[i:i+4]) == -4 for i in range(len(sequence) - 3))\n",
    "\n",
    "    # check rows\n",
    "    for row in state:\n",
    "        if is_winning_sequence(row):\n",
    "            return 1 if any(cell == 1 for cell in row) else -1\n",
    "\n",
    "    # check columns\n",
    "    for col in range(len(state[0])):\n",
    "        column_values = [state[row][col] for row in range(len(state))]\n",
    "        if is_winning_sequence(column_values):\n",
    "            return 1 if any(cell == 1 for cell in column_values) else -1\n",
    "\n",
    "    # check diagonals\n",
    "    for row in range(len(state) - 3):\n",
    "        for col in range(len(state[0]) - 3):\n",
    "            diagonal_values = [state[row + i][col + i] for i in range(4)]\n",
    "            anti_diagonal_values = [state[row + 3 - i][col + i] for i in range(4)]\n",
    "\n",
    "            if is_winning_sequence(diagonal_values):\n",
    "                return 1 if any(cell == 1 for cell in diagonal_values) else -1\n",
    "\n",
    "            if is_winning_sequence(anti_diagonal_values):\n",
    "                return 1 if any(cell == 1 for cell in anti_diagonal_values) else -1\n",
    "\n",
    "    # check ties\n",
    "    if all(cell != 0 for row in state for cell in row):\n",
    "        return 0\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def available_actions(board, player, mean_allowed):\n",
    "    actions = []\n",
    "\n",
    "    for column in range(len(board[0])):\n",
    "        if board[0][column] == 0: \n",
    "            actions.append(('drop', column))\n",
    "        last_row = len(board) - 1\n",
    "        if mean_allowed:\n",
    "            if board[last_row][column] == -player and board[last_row - 1][column] != 0:\n",
    "                actions.append(('mean', column))\n",
    "\n",
    "    return actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T7SYQM4L8cl"
   },
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the game state and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(state, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "g0uUKNKNL8cl"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_player(board, player = None, mean_allowed = True):\n",
    "    return random.choice(available_actions(board, player, mean_allowed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS3yOFlbL8cl"
   },
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "55tvNH3vL8cl",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 783, '-1': 217, '0': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def switch_player(player):\n",
    "    if player == 1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def play(N = 1000):\n",
    "    \"\"\"Let two agents play each other N times. x starts. x and y are agent functions that \n",
    "    get the board as the percept and return their next action.\"\"\"\n",
    "    results = {'1': 0, '-1': 0, '0': 0}\n",
    "    \n",
    "    mean_allowed = True\n",
    "    \n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player = 1\n",
    "        \n",
    "        while True:\n",
    "            action = random_player(board, player, mean_allowed)\n",
    "            \n",
    "            if action[0] == 'mean':\n",
    "                mean_allowed = False\n",
    "            else:\n",
    "                mean_allowed = True\n",
    "            \n",
    "            board = move(board, action, player)\n",
    "            \n",
    "            win = check_board(board)   # returns the None if the game is not done.\n",
    "            if win:\n",
    "                results[str(win)] += 1\n",
    "                break\n",
    "            \n",
    "            player = switch_player(player)   \n",
    "    \n",
    "    return results\n",
    "\n",
    "play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvzOxRDpL8cm"
   },
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [3 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given state and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__\n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 \\times 4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJ2xQLrWL8cm"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQeK9qFXL8cm"
   },
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECcMh7WTL8cm"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ByI_b2VL8cm"
   },
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kG2qLFIL8cm"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDHTe0LcL8cn"
   },
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omeYo7HyL8cn"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_ZJDd9nL8cn"
   },
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip9dbCRgL8cn"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhk1YRnDL8cn"
   },
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx1qffv2L8co"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXE2i58iL8co"
   },
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points]\n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoCQIXw_L8co"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbIviqR6L8co"
   },
   "source": [
    "### Cutting off search\n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhKCwDTPL8co"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBpYGvxBL8co"
   },
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHqb_K5YL8co"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaBC7W7VL8cp"
   },
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yb303vWbL8cp"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bokyrXrkL8cp"
   },
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUILjLbdL8cp"
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFhDH9M_L8cp"
   },
   "source": [
    "---\n",
    "Assignment adapted from [Michael Hahsler](https://github.com/mhahsler/CS7320-AI) under [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0/deed.en) license.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
